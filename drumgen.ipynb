{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import soundfile as sf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(xpath,ypath):\n",
    "    def normalize(qt,target):\n",
    "        mfcc_min = torch.min(qt)\n",
    "        mfcc_max = torch.max(qt)\n",
    "        qt = (qt - mfcc_min) / (mfcc_max - mfcc_min)\n",
    "        #qt = (qt -0.5)/0.5\n",
    "        \n",
    "        mfcc_min2 = torch.min(target)\n",
    "        mfcc_max2 = torch.max(target)\n",
    "        target = (target - mfcc_min2) / (mfcc_max2 - mfcc_min2)\n",
    "        #target = (target -0.5)/0.5\n",
    "        return qt,target,mfcc_min2,mfcc_max2\n",
    "    \n",
    "\n",
    "    song,sr = librosa.load(xpath)\n",
    "    mel = librosa.feature.melspectrogram(y=song,sr=sr,n_fft=2048,hop_length=512)\n",
    "    mel= [librosa.power_to_db(mel)]\n",
    "    \"\"\" librosa.display.specshow(data=mel,x_axis=\"time\",y_axis=\"mel\")\n",
    "    plt.colorbar(format='%+2.0f dB') \"\"\"\n",
    "    qt= torch.Tensor(mel) \n",
    "    \n",
    "    drum,sr2=librosa.load(ypath)\n",
    "    label = librosa.feature.melspectrogram(y=drum,sr=sr2,n_fft=2048,hop_length=512)\n",
    "    label= [librosa.power_to_db(label)]\n",
    "    \"\"\" librosa.display.specshow(data=label,x_axis=\"time\",y_axis=\"mel\")\n",
    "    plt.colorbar(format='%+2.0f dB') \"\"\"\n",
    "    target = torch.Tensor(label) \n",
    "    \n",
    "\n",
    "     \n",
    "    \n",
    "        \n",
    "    return normalize(qt,target)\n",
    "\n",
    "a,target,_,_= load_data(\"test/012146 [music].wav\",\"test/012146 [drums].wav\")    \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dir1,dir2, transform=None, target_transform=None):\n",
    "        self.music =dir1\n",
    "        self.drum = dir2\n",
    "        self.musicdir = os.listdir(dir1)\n",
    "        self.drumdir = os.listdir(dir2)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.musicdir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        music_path = os.path.join(self.music, self.musicdir[idx])\n",
    "        drum_path = os.path.join(self.drum, self.drumdir[idx])\n",
    "        mus,dr,m1,m2 = load_data(music_path,drum_path)\n",
    "        \n",
    "        return mus,dr,m1,m2\n",
    "    \n",
    "training_data = CustomDataset(\"D:\\Seperated\\BassTrainData\",\"D:\\Seperated\\DrumTrainData\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self,latspa):\n",
    "        super(Network,self).__init__()\n",
    "        self.latspa =latspa\n",
    "        self.cnn= nn.Sequential(\n",
    "            nn.Conv2d(1,4,3,1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(4,16,3,1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16,1,3,1),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "        )\n",
    "       \n",
    "            \n",
    "        self.rnn=nn.LSTM(53,128)\n",
    "        self.rnn2=nn.LSTM(128,128)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.encoder=nn.Sequential(\n",
    "            \n",
    "            #TRIED LEAKY RELU 0.1 BUT GAVE NEGATIVE VALUES ON KL DIVERGENCE, WHICH IS MU AND SIGMA WHIC IS UNACCEPTABLE\n",
    "            nn.Linear(128,512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512,64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(32,latspa)\n",
    "    \n",
    "        )\n",
    "        self.mu = nn.Sequential(\n",
    "            nn.Linear(latspa,latspa),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dev = nn.Sequential(\n",
    "            nn.Linear(latspa,latspa),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.convtrans=nn.Sequential(\n",
    "            nn.ConvTranspose2d(1,4,4,2,1,output_padding=(0,1)),\n",
    "            nn.ConvTranspose2d(4,4,4,2,1,output_padding=(0,1)),\n",
    "            nn.ConvTranspose2d(4,1,4,2,1,output_padding=(0,1)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "            \n",
    "            \n",
    "            nn.Linear(latspa,32),\n",
    "            nn.Linear(32,64),\n",
    "            nn.Linear(64,128),\n",
    "            nn.Linear(128,848)\n",
    "            \n",
    "           \n",
    "            \n",
    "        )\n",
    "    \n",
    "    def encode(self,nm):\n",
    "        out = self.cnn(nm)\n",
    "        out= out.transpose(1,0)[0]\n",
    "        out = out.transpose(1,0)\n",
    "        out,_ = self.rnn(out)\n",
    "        out,_ = self.rnn2(out)\n",
    "        out=out[0]\n",
    "        a = self.encoder(out)\n",
    "        mu = self.mu(a)\n",
    "        dev = self.dev(a)\n",
    "\n",
    "\n",
    "        return mu,dev\n",
    "    \n",
    "    def reparametrize(self, mu, log_var):\n",
    "\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self,mfcc):\n",
    "        \n",
    "        mu,dev=self.encode(mfcc)\n",
    "        z = self.reparametrize(mu,dev)\n",
    "        temp = self.decoder(z)\n",
    "        temp=temp.view(16,1,16,53)\n",
    "        temp = self.convtrans(temp)\n",
    "        temp= temp.transpose(1,0)[0]\n",
    "        return  temp,mu,dev\n",
    "    \n",
    "    def sample(self):\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(1,self.latspa)\n",
    "            return self.decoder(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lf(nn.Module):\n",
    "    def __init__(self,beta):\n",
    "        super(lf, self).__init__()\n",
    "        self.beta=beta\n",
    "    def forward(self,a,mu,det,target):\n",
    "        target= target.transpose(1,0)[0]\n",
    "        L1= nn.functional.mse_loss(a,target)\n",
    "        L2=torch.mean((0.5*(torch.pow(det,2) + torch.pow(mu,2) - torch.log(det+1e-7) - 1)))\n",
    "    \n",
    "        return (L1 +self.beta*L2,L2)\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 3e-4\n",
    "latspa=8\n",
    "model=Network(latspa)\n",
    "optimizer=torch.optim.Adam(params=model.parameters(),lr=lr)\n",
    "epoch=60\n",
    "beta=0.1\n",
    "loss_fn =lf(beta)\n",
    "batch_size =16\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "def train_loop(x,y,ep,i):\n",
    "   \n",
    "    x=x.to(device)\n",
    "    y=y.to(device)\n",
    "    \n",
    "\n",
    "    a,mu,det= model(x)\n",
    "            \n",
    "            \n",
    "           \n",
    "    optimizer.zero_grad()\n",
    "    loss=loss_fn(a,mu,det,y)\n",
    "            \n",
    "    loss[0].backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch: {ep+1},batch: {i+1}, loss: {loss[0].item()}, KL: {loss[1].item()}\")\n",
    "                 \n",
    "for ep in range(epoch):\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        if data[0].shape[0]==batch_size:\n",
    "            train_loop(data[0],data[1],ep,i)\n",
    "         \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= next(iter(train_dataloader))\n",
    "\n",
    "b=model(a[0])\n",
    "audio = b[0][0]\n",
    "\n",
    "mfccmin = a[2][0]\n",
    "mfccmax = a[3][0]\n",
    "#audio = audio *0.5 + 0.5\n",
    "audio =audio * (mfccmax-mfccmin) +mfccmin\n",
    "\n",
    "aud=audio.detach().cpu().numpy()\n",
    "aud=librosa.db_to_power(aud)\n",
    "aud = librosa.feature.inverse.mel_to_audio(M=aud)\n",
    "sf.write('stereo_file_MoreData.wav', data= aud, samplerate=22050,subtype='PCM_24') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "song,sr = librosa.load(\"test/012146 [drums].wav\")\n",
    "mel = librosa.feature.melspectrogram(y=song,sr=sr,n_fft=2048,hop_length=512)\n",
    "mel= librosa.power_to_db(mel)\n",
    "mel=librosa.db_to_power(mel)\n",
    "mel = librosa.feature.inverse.mel_to_audio(M=mel)\n",
    "sf.write('test.wav', data= mel, samplerate=22050,subtype='PCM_24') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
