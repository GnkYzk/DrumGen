{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import torch\n",
    "from torch import nn\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  7.9914,  22.2119,  27.1174,  ...,  -7.8436,  -6.8130,  -6.8313],\n",
      "        [  0.9804,   5.9902,   8.9781,  ..., -20.5102, -20.9072, -18.0265],\n",
      "        [ -9.0411,   3.2090,   8.1580,  ..., -18.9686, -20.5764, -19.6286],\n",
      "        ...,\n",
      "        [-28.4808, -15.5823, -16.1480,  ..., -42.0983, -41.5222, -45.1540],\n",
      "        [-32.9772, -21.3262, -22.2353,  ..., -41.1312, -43.8570, -48.3076],\n",
      "        [-34.0898, -24.6650, -26.9874,  ..., -41.7350, -43.5231, -47.1973]])\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor([[0.7152, 0.8929, 0.9542,  ..., 0.5172, 0.5301, 0.5299],\n",
      "        [0.6275, 0.6901, 0.7275,  ..., 0.3589, 0.3539, 0.3899],\n",
      "        [0.5023, 0.6554, 0.7172,  ..., 0.3782, 0.3581, 0.3699],\n",
      "        ...,\n",
      "        [0.2593, 0.4205, 0.4134,  ..., 0.0890, 0.0962, 0.0508],\n",
      "        [0.2031, 0.3487, 0.3373,  ..., 0.1011, 0.0671, 0.0114],\n",
      "        [0.1891, 0.3070, 0.2779,  ..., 0.0936, 0.0712, 0.0253]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[3.4869e-06, 3.5090e-05, 3.7245e-05,  ..., 1.2123e-04, 1.2415e-04,\n",
       "          6.8595e-05],\n",
       "         [2.1949e-06, 1.4804e-05, 1.4066e-05,  ..., 8.2509e-04, 1.7922e-03,\n",
       "          1.2612e-03],\n",
       "         [6.3812e-07, 5.6054e-06, 2.5213e-05,  ..., 1.9554e-03, 5.9118e-03,\n",
       "          5.4022e-03],\n",
       "         ...,\n",
       "         [2.2719e-09, 3.3459e-08, 1.0234e-07,  ..., 6.6871e-09, 1.7154e-08,\n",
       "          6.7842e-08],\n",
       "         [2.0751e-09, 1.4556e-08, 7.3961e-08,  ..., 1.8965e-09, 1.3494e-08,\n",
       "          6.2712e-08],\n",
       "         [1.0184e-10, 1.3141e-09, 9.0720e-09,  ..., 1.5110e-10, 6.1186e-09,\n",
       "          3.2221e-08]]),\n",
       " tensor([[0.7152, 0.8929, 0.9542,  ..., 0.5172, 0.5301, 0.5299],\n",
       "         [0.6275, 0.6901, 0.7275,  ..., 0.3589, 0.3539, 0.3899],\n",
       "         [0.5023, 0.6554, 0.7172,  ..., 0.3782, 0.3581, 0.3699],\n",
       "         ...,\n",
       "         [0.2593, 0.4205, 0.4134,  ..., 0.0890, 0.0962, 0.0508],\n",
       "         [0.2031, 0.3487, 0.3373,  ..., 0.1011, 0.0671, 0.0114],\n",
       "         [0.1891, 0.3070, 0.2779,  ..., 0.0936, 0.0712, 0.0253]]),\n",
       " tensor(-49.2216),\n",
       " tensor(30.7784))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data():\n",
    "    def normalize(input,target):\n",
    "        mfcc_min = torch.min(input)\n",
    "        mfcc_max = torch.max(input)\n",
    "        input = (input - mfcc_min) / (mfcc_max - mfcc_min)\n",
    "\n",
    "        print(target)\n",
    "        mfcc_min2 = torch.min(target)\n",
    "        mfcc_max2 = torch.max(target)\n",
    "        target = (target - mfcc_min2) / (mfcc_max2 - mfcc_min2)\n",
    "        print(torch.min(target))\n",
    "        print(torch.max(target))\n",
    "        print(target)\n",
    "        return input,target,mfcc_min2,mfcc_max2\n",
    "    \n",
    "\n",
    "    song,sr = librosa.load(\"test/012146 [music].wav\")\n",
    "    #song, _ = librosa.magphase(song)\n",
    "    mel = librosa.feature.melspectrogram(y=song,sr=sr,n_fft=2048,hop_length=512)\n",
    "    #mel= librosa.power_to_db(mel, ref=np.min)\n",
    "    #librosa.display.specshow(data=mel,x_axis=\"time\",y_axis=\"mel\")\n",
    "    #plt.colorbar(format='%+2.0f dB')\n",
    "    input= torch.Tensor(mel) \n",
    "\n",
    "    drum,sr2=librosa.load(\"test/012146 [drums].wav\")\n",
    "    drum, _ = librosa.magphase(drum)\n",
    "    label = librosa.feature.melspectrogram(y=drum,sr=sr2,n_fft=2048,hop_length=512)\n",
    "    label= librosa.power_to_db(label)\n",
    "    \n",
    "\n",
    "    \"\"\" librosa.display.specshow(data=label,x_axis=\"time\",y_axis=\"mel\")\n",
    "    plt.colorbar(format='%+2.0f dB') \"\"\"\n",
    "    target = torch.Tensor(label) \n",
    "    \n",
    "\n",
    "     \n",
    "    \n",
    "        \n",
    "    return normalize(input,target)\n",
    "\n",
    "    \n",
    "\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module): #NOT BATCHED FOR NOW\n",
    "    def __init__(self,latspa):\n",
    "        super().__init__()\n",
    "        self.latspa =latspa\n",
    "        self.cnn= nn.Sequential(\n",
    "            nn.Conv2d(1,4,3,1,1),\n",
    "            nn.Conv2d(4,8,3,1,1),\n",
    "            nn.Conv2d(8,16,3,1,1),\n",
    "            nn.Conv2d(16,1,3,1,1)\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.rnn1=nn.LSTM(1293,512)\n",
    "        self.rnn2=nn.LSTM(512,512)\n",
    "        self.rnn3=nn.LSTM(512,256)\n",
    "        self.rnn4=nn.LSTM(256,128)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.encoder=nn.Sequential(\n",
    "            \n",
    "            nn.Linear(128,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,latspa)\n",
    "    \n",
    "        )\n",
    "        self.mu = nn.Linear(latspa,latspa)\n",
    "        self.dev = nn.Linear(latspa,latspa)\n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "\n",
    "            nn.Linear(latspa,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,165504),\n",
    "            nn.Sigmoid()\n",
    "           \n",
    "            \n",
    "        )\n",
    "        \n",
    "    def encode(self,nm):\n",
    "        \n",
    "        nm=nm.unsqueeze(0)\n",
    "        cnn = self.cnn(nm)\n",
    "        cnn=cnn[0]\n",
    "\n",
    "        out,_ = self.rnn1(cnn)\n",
    "        out,_ = self.rnn2(out)\n",
    "        out,_ = self.rnn3(out)\n",
    "        out,_ = self.rnn4(out)\n",
    "        out = out[-1]\n",
    "\n",
    "        a = self.encoder(out)\n",
    "        mu = self.mu(a)\n",
    "        dev = self.dev(a)\n",
    "\n",
    "        return mu,dev\n",
    "    \n",
    "    def reparametrize(self, mu, log_var):\n",
    "\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self,mfcc):\n",
    "        \n",
    "        mu,dev=self.encode(mfcc)\n",
    "        z = self.reparametrize(mu,dev)\n",
    "        temp = self.decoder(z)\n",
    "        return  temp.view(128,1293) ,mu,dev\n",
    "    \n",
    "    def sample(self):\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(1,self.latspa)\n",
    "            return self.decoder(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(a,mu,det,target,beta):\n",
    "    \n",
    "    L1= nn.functional.mse_loss(a,target)\n",
    "    L2= beta*(-0.5 * torch.sum(1 + det - mu.pow(2) - det.exp()))\n",
    "    \n",
    "    return L1 +L2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 1e-4\n",
    "latspa=8 \n",
    "model=Network(latspa)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "epoch=1000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_loop(input,target):\n",
    "    for _ in range(epoch):\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        a,mu,det= model(input)\n",
    "        optimizer.zero_grad()\n",
    "        loss=loss_function(a,mu,det,target)\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  7.9914,  22.2119,  27.1174,  ...,  -7.8436,  -6.8130,  -6.8313],\n",
      "        [  0.9804,   5.9902,   8.9781,  ..., -20.5102, -20.9072, -18.0265],\n",
      "        [ -9.0411,   3.2090,   8.1580,  ..., -18.9686, -20.5764, -19.6286],\n",
      "        ...,\n",
      "        [-28.4808, -15.5823, -16.1480,  ..., -42.0983, -41.5222, -45.1540],\n",
      "        [-32.9772, -21.3262, -22.2353,  ..., -41.1312, -43.8570, -48.3076],\n",
      "        [-34.0898, -24.6650, -26.9874,  ..., -41.7350, -43.5231, -47.1973]])\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor([[0.7152, 0.8929, 0.9542,  ..., 0.5172, 0.5301, 0.5299],\n",
      "        [0.6275, 0.6901, 0.7275,  ..., 0.3589, 0.3539, 0.3899],\n",
      "        [0.5023, 0.6554, 0.7172,  ..., 0.3782, 0.3581, 0.3699],\n",
      "        ...,\n",
      "        [0.2593, 0.4205, 0.4134,  ..., 0.0890, 0.0962, 0.0508],\n",
      "        [0.2031, 0.3487, 0.3373,  ..., 0.1011, 0.0671, 0.0114],\n",
      "        [0.1891, 0.3070, 0.2779,  ..., 0.0936, 0.0712, 0.0253]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input,target,mfccmin,mfccmax= load_data()\n",
    "train_loop(input,target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  7.9914,  22.2119,  27.1174,  ...,  -7.8436,  -6.8130,  -6.8313],\n",
      "        [  0.9804,   5.9902,   8.9781,  ..., -20.5102, -20.9072, -18.0265],\n",
      "        [ -9.0411,   3.2090,   8.1580,  ..., -18.9686, -20.5764, -19.6286],\n",
      "        ...,\n",
      "        [-28.4808, -15.5823, -16.1480,  ..., -42.0983, -41.5222, -45.1540],\n",
      "        [-32.9772, -21.3262, -22.2353,  ..., -41.1312, -43.8570, -48.3076],\n",
      "        [-34.0898, -24.6650, -26.9874,  ..., -41.7350, -43.5231, -47.1973]])\n",
      "tensor(0.)\n",
      "tensor(1.)\n",
      "tensor([[0.7152, 0.8929, 0.9542,  ..., 0.5172, 0.5301, 0.5299],\n",
      "        [0.6275, 0.6901, 0.7275,  ..., 0.3589, 0.3539, 0.3899],\n",
      "        [0.5023, 0.6554, 0.7172,  ..., 0.3782, 0.3581, 0.3699],\n",
      "        ...,\n",
      "        [0.2593, 0.4205, 0.4134,  ..., 0.0890, 0.0962, 0.0508],\n",
      "        [0.2031, 0.3487, 0.3373,  ..., 0.1011, 0.0671, 0.0114],\n",
      "        [0.1891, 0.3070, 0.2779,  ..., 0.0936, 0.0712, 0.0253]])\n",
      "[[1.3338641e-09 1.1576993e-09 9.8089159e-10 ... 1.2593799e-09\n",
      "  1.2445700e-09 1.0242175e-09]\n",
      " [1.2530161e-09 1.1388139e-09 1.2151290e-09 ... 1.0904033e-09\n",
      "  1.3582520e-09 1.3103687e-09]\n",
      " [1.4854298e-09 1.0808177e-09 1.4941448e-09 ... 1.3495410e-09\n",
      "  1.1493378e-09 1.1611160e-09]\n",
      " ...\n",
      " [9.8104025e-10 1.2401395e-09 1.2436794e-09 ... 1.1334723e-09\n",
      "  1.2750155e-09 1.1673950e-09]\n",
      " [1.1259383e-09 1.1179168e-09 1.4733967e-09 ... 1.2942996e-09\n",
      "  1.1189286e-09 1.2918122e-09]\n",
      " [1.2124237e-09 1.0596599e-09 1.0943662e-09 ... 1.2683721e-09\n",
      "  1.1998562e-09 1.0548588e-09]]\n",
      "[ 1.9422587  -0.0865574  -0.44318905 ...  0.49653414  3.8009434\n",
      " -1.5032034 ]\n"
     ]
    }
   ],
   "source": [
    "input,target,mfccmin,mfccmax= load_data()\n",
    "audio,mu,det=model(input)\n",
    "\n",
    "\n",
    "audio =audio * (mfccmin-mfccmax) +mfccmin\n",
    "\n",
    "aud=audio.detach().cpu().numpy()\n",
    "aud=librosa.db_to_power(aud)\n",
    "print(aud)\n",
    "aud = librosa.feature.inverse.mel_to_audio(M=aud)\n",
    "print(aud)\n",
    "sf.write('stereo_file.wav', data= aud, samplerate=22050,subtype='PCM_24') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
